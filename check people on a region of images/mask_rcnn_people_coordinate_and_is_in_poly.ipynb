{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ceb8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1507d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import colorsys\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d807cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--input\", type=str, default=None,\n",
    "\thelp=\"path to input video file\")\n",
    "ap.add_argument('-f', \"--folder\", type=str, default=None, help=\"path to input video folder\")\n",
    "ap.add_argument(\"-o\", \"--output\", type=str, default=\"./output\", help=\"path to output images folder\")\n",
    "ap.add_argument(\"-s\", \"--source\", type=str, default=\"./source\", help=\"path to save sorce video to image folder\")\n",
    "ap.add_argument(\"-c\", \"--csvfolder\", type=str, default=\"./csvfiles\", help=\"path to output csv files folder\")\n",
    "ap.add_argument(\"-e\", \"--extendsion\", type=str, default=\"mp4\", help=\"video extendsion file\")\n",
    "ap.add_argument(\"--fps\", type=int, default=30, help=\"count video to image per frame\")\n",
    "ap.add_argument(\"-r\", \"--result\", type=int, default=1, help='whether storage source and result image')\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfcde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project: current directory\n",
    "pathProject = os.getcwd()\n",
    "pathLib     = os.path.sep.join([pathProject,\"lib\"])\n",
    "#testing dataset\n",
    "videoPath = args[\"input\"]\n",
    "videoFolder = args[\"folder\"]\n",
    "inputPath   = args[\"input\"]\n",
    "csvfolder = args[\"csvfolder\"]\n",
    "fps = args['fps']\n",
    "outputPath  = args[\"output\"]\n",
    "if args['result'] == 1:\n",
    "    save = True\n",
    "else:\n",
    "    save = False\n",
    "sorucePath = args['source']\n",
    "labelsPath  = os.path.sep.join([pathLib, \"coco_labels.txt\"])\n",
    "weightsPath = os.path.sep.join([pathLib, \"mask_rcnn_coco.h5\"])\n",
    "\n",
    "color={\"red\":(0,0,255),\"green\":(0,255,0),\"blue\":(255,0,0),\n",
    "       \"yellow\":(0,255,255),\"cyan\":(255,255,0)} #BGR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfb2aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Mask R-CNN model...\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\maskrcnn\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# load the class label names from disk, one label per line\n",
    "CLASS_NAMES = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# generate random (but visually distinct) colors for each class label\n",
    "# (thanks to Matterport Mask R-CNN for the method!)\n",
    "hsv = [(i / len(CLASS_NAMES), 1, 1.0) for i in range(len(CLASS_NAMES))]\n",
    "COLORS = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "random.seed(42)\n",
    "random.shuffle(COLORS)\n",
    "\n",
    "class SimpleConfig(Config):\n",
    "    # give the configuration a recognizable name\n",
    "    NAME = \"coco_inference\"\n",
    "    # set the number of GPUs to use along with the number of images per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # number of classes (we would normally add +1 for the background\n",
    "    # but the background class is *already* included in the class names)\n",
    "    NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# initialize the inference configuration\n",
    "config = SimpleConfig()\n",
    "\n",
    "# initialize the Mask R-CNN model for inference and then load the weights\n",
    "print(\"[INFO] loading Mask R-CNN model...\")\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config,\tmodel_dir=os.getcwd())\n",
    "model.load_weights(weightsPath, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fea6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_rcnn(image, convertSize, showName=False, showNumberOfPerson=False):\n",
    "    img = image.copy()\n",
    "    # perform a forward pass of the network to obtain the results\n",
    "    print(\"[INFO] making predictions with Mask R-CNN...\")\n",
    "    color = (0,255,0) #BGR\n",
    "    width_img   = img.shape[1] #x\n",
    "    ratio = convertSize/width_img\n",
    "    img = imutils.resize(img, width=convertSize)\n",
    "    \n",
    "    #detect results   \n",
    "    r = model.detect([img], verbose=1)[0]\n",
    "    \n",
    "    #convert the image back to BGR so we can use OpenCV's drawing functions\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    count  = 0 #count people\n",
    "    bboxes = [] #boxes in image\n",
    "    #loop over the predicted scores and class labels\n",
    "    for i in range(0, len(r[\"scores\"])):\n",
    "    #extract the bounding box information, class ID, label, predicted probability, and visualization color\n",
    "        classID = r[\"class_ids\"][i]\n",
    "        label   = CLASS_NAMES[classID]\n",
    "        if label != \"person\": #check person class\n",
    "            continue\n",
    "        \n",
    "        count  = count + 1\n",
    "        (startY, startX, endY, endX) = r[\"rois\"][i] #get bbox\n",
    "        #covert to original codinate\n",
    "        startY = int(startY/ratio)\n",
    "        startX = int(startX/ratio)\n",
    "        endY   = int(endY/ratio)\n",
    "        endX   = int(endX/ratio)\n",
    "        bbox = [startY, startX, endY, endX]\n",
    "        bboxes.append(bbox)\n",
    "        img = imutils.resize(img, width=width_img) #covert image to orginal size\n",
    "        \n",
    "        #draw the bounding box\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), color, 2)\n",
    "        #show class label, and score of the object\n",
    "        if showName:\n",
    "            #score = r[\"scores\"][i]\n",
    "            #text = \"{}: {:.3f}\".format(label, score)\n",
    "            text =\"#\"+str(count)\n",
    "            y    = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.putText(img, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "      #Total of boxs\n",
    "    if showNumberOfPerson:\n",
    "        cv2.putText(img, str(len(bboxes)),(10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 2)\n",
    "            \n",
    "    return img, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./my_images/image4.jpg\")\n",
    "img = cv2.resize(img, (1800, 1000), interpolation=cv2.INTER_AREA)\n",
    "overlay = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd2a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] making predictions with Mask R-CNN...\n",
      "Processing 1 images\n",
      "image                    shape: (284, 512, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  146.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "[[130, 791, 196, 819], [140, 660, 193, 682], [116, 1307, 154, 1321], [123, 1346, 168, 1371]]\n"
     ]
    }
   ],
   "source": [
    "bb=[]\n",
    "widthMask= 512 #image size for Mask RCNN\n",
    "\n",
    "crop_img,bb = mask_rcnn(img, widthMask)\n",
    "\n",
    "cv2.imwrite('crop_img.jpg', crop_img)\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989c29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((bb[0][1] + bb[0][3])/2, (bb[0][0] + bb[0][2])/2) \n",
    "#print((bb[1][1] + bb[1][3])/2, (bb[1][0] + bb[1][2])/2)\n",
    "#print((bb[2][1] + bb[2][3])/2, (bb[2][0] + bb[2][2])/2)\n",
    "#print((bb[3][1] + bb[3][3])/2, (bb[3][0] + bb[3][2])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a947b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[805.0, 163.0], [671.0, 166.5], [1314.0, 135.0], [1358.5, 145.5]]\n"
     ]
    }
   ],
   "source": [
    "list_f = []\n",
    "for i in range(len(bb)):\n",
    "    x = (bb[i][1] + bb[i][3])/2\n",
    "    y = (bb[i][0] + bb[i][2])/2\n",
    "    \n",
    "    list_f.append([x, y])\n",
    "print(list_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc6fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_poly(p, poly):\n",
    "    \"\"\"\n",
    "\n",
    "    :param p: [x, y]\n",
    "    :param poly: [[], [], [], [], ...]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    px, py = p\n",
    "    is_in = False\n",
    "    for i, corner in enumerate(poly):\n",
    "        next_i = i + 1 if i + 1 < len(poly) else 0\n",
    "        x1, y1 = corner\n",
    "        x2, y2 = poly[next_i]\n",
    "        if (x1 == px and y1 == py) or (x2 == px and y2 == py):  # if point is on vertex\n",
    "            is_in = True\n",
    "            break\n",
    "        if min(y1, y2) < py <= max(y1, y2):  # find horizontal edges of polygon\n",
    "            x = x1 + (py - y1) * (x2 - x1) / (y2 - y1)\n",
    "            if x == px:  # if point is on edge\n",
    "                is_in = True\n",
    "                break\n",
    "            elif x > px:  # if point is on left-side of line\n",
    "                is_in = not is_in\n",
    "    return is_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ffa87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = list_f\n",
    "\n",
    "poly = [[50, 50], [1750, 30], [1500, 350], [30, 800]]\n",
    "\n",
    "points2 = np.array([[50, 50], [1750, 30], [1500, 350], [30, 800]])\n",
    "\n",
    "light_red = (0, 0, 255)\n",
    "light_green = (144, 238, 144)\n",
    "\n",
    "for per_person in person: \n",
    "    if is_in_poly(per_person, poly) == True:\n",
    "       #points2 = np.array([[50, 50], [1400, 30], [1500, 380], [30, 800]])\n",
    "       #light_red = (0, 0, 255)\n",
    "       cv2.fillPoly(img, [points2], light_red)\n",
    "    \n",
    "       alpha = 0.4  # Transparency factor.\n",
    "\n",
    "       # Following line overlays transparent rectangle over the image\n",
    "       img_new = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)\n",
    "       cv2.imwrite('colored_region.jpg', img_new)\n",
    "\n",
    "    else:\n",
    "       cv2.fillPoly(img, [points2], light_green)\n",
    "    \n",
    "       alpha = 0.4  # Transparency factor.\n",
    "\n",
    "       # Following line overlays transparent rectangle over the image\n",
    "       img_new = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)\n",
    "       cv2.imwrite('colored_region.jpg', img_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa4bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
